{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97jDW6dhYI0_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W00nRD-WTTXR",
        "outputId": "4ee3af21-5002-499a-9af1-3091571aa3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Installing the dependencies\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kY4nzCvpytU7",
        "outputId": "ea81bca0-2cee-40ab-865e-d42aaa5aeb4f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setting up the device agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ESmIwbKy1d0",
        "outputId": "ab2eee7c-76ae-4b25-dd64-acfe7b66e607"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:26<00:00, 57.4MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Loading up the whisper model for the audio trainscription\n",
        "\n",
        "model = whisper.load_model(\"medium.en\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CtMIpc1_zESh",
        "outputId": "b4b44f65-2e86-4206-97ea-a1e97b1c82bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/audio.mp4'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mentioning the youtube video and downloading the audio from the youtube video\n",
        "\n",
        "video_url = 'https://www.youtube.com/watch?v=Sby1uJ_NFIY'\n",
        "yt = YouTube(video_url)\n",
        "video = yt.streams.filter(only_audio=True).first()\n",
        "filename = \"audio.mp4\"\n",
        "video.download(filename=filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7xyncgizk6e",
        "outputId": "cff36279-32f9-477c-d589-e2eb496b96aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "audio = \"audio.\"\n",
        "result = model.transcribe(\"Trippy.mp3\")\n",
        "output_directory = \"./\"\n",
        "\n",
        "\n",
        "# Save as an SRT file\n",
        "srt_writer = get_writer(\"srt\", output_directory)\n",
        "srt_writer(result, audio)\n",
        "\n",
        "\n",
        "# Save as a VTT file\n",
        "vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "vtt_writer(result, audio)\n",
        "\n",
        "# txt_path = file_path.with_suffix(\".txt\")\n",
        "# print(f\"\\nCreating text file\")\n",
        "\n",
        "# with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "#     txt.write(result[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_bGcoN_bqzvN"
      },
      "outputs": [],
      "source": [
        "txt_writer = get_writer(\"txt\", output_directory)\n",
        "txt_writer(result, audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3MfQL9GxXJP",
        "outputId": "53e4a5e6-f355-40a8-f863-4080b9cdf247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, so I'm not feeling very well today\n",
            "I was feeling a bit nauseous in the morning and I had a bit of temperature\n",
            "So what can you suggest me for for the medications?\n",
            "I have not prescribed to any doctor, but I want some\n",
            "medications for home remedies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Open the file in read mode\n",
        "with open('/content/audio.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Now you can use the 'text' variable\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evGzwh4cyMif"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Read the VTT file\n",
        "with open(\"audio.vtt\", \"r\") as file:\n",
        "    vtt_content = file.read()\n",
        "\n",
        "# Extract timestamps and text segments\n",
        "pattern = r\"(\\d+:\\d+\\.\\d+) --> (\\d+:\\d+\\.\\d+)\\n(.+?)\\n\\n\"\n",
        "matches = re.findall(pattern, vtt_content, re.DOTALL)\n",
        "\n",
        "# Calculate start and end times for each segment\n",
        "aligned_segments = []\n",
        "for match in matches:\n",
        "    start_time = match[0]\n",
        "    end_time = match[1]\n",
        "    text = match[2].strip()\n",
        "\n",
        "    # Convert timestamp to seconds\n",
        "    start_seconds = sum(float(x) * 60 ** i for i, x in enumerate(reversed(start_time.split(\":\"))))\n",
        "    end_seconds = sum(float(x) * 60 ** i for i, x in enumerate(reversed(end_time.split(\":\"))))\n",
        "\n",
        "    # Append the aligned segment\n",
        "    aligned_segments.append({\"start_time\": start_seconds, \"end_time\": end_seconds, \"text\": text})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bnhjyrHMyRWy"
      },
      "outputs": [],
      "source": [
        "aligned_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG__0gFMtn7r",
        "outputId": "04a810fb-f7f1-4231-926e-e0ea26aba953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.7-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.7\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EO3v2Pm4rHet"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"OPENAI_KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-16k\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"You are a virtual doctor. You respond empathetically and ensure to understand the user's root cause of the problem. You provide safe medicines and do not prescribe any suspicious or unsafe medications. You answer only questions related to healthcare.\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": f\"The users problem is :{text}\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "\n",
        "# print(\"Content: \", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "U2JePXBOtlWY",
        "outputId": "f508d950-3a4b-40d8-b7d9-cbc8bec4346c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry to hear that you're not feeling well. It's important to understand the root cause of your symptoms before recommending any medications. Nausea and mild fever can be caused by various factors such as a viral infection, food poisoning, or even just a common cold.\\n\\nInstead of prescribing medications, I can suggest some general home remedies that might help you feel better:\\n\\n1. Stay hydrated: Drink plenty of fluids like water, herbal tea, or clear broth to stay hydrated and prevent further dehydration.\\n\\n2. Rest: Get enough rest and avoid any strenuous activities until you start feeling better.\\n\\n3. Ginger: Ginger has been known to ease nausea. You can try sipping on ginger tea or chewing on a small piece of ginger.\\n\\n4. Avoid heavy meals: Stick to bland, easy-to-digest foods like toast, rice, or bananas until your symptoms subside.\\n\\nHowever, if your symptoms worsen or persist for more than a few days, it's important to consult a healthcare professional for a proper diagnosis and appropriate treatment.\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content = response.choices[0].message.content\n",
        "content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UaT-CxQKXIVE"
      },
      "outputs": [],
      "source": [
        "VOICE_ID = \"nxo2TAmShnYtYe9wngSQ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0pFqXwfW5dwe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "CHUNK_SIZE = 1024\n",
        "url = \"https://api.elevenlabs.io/v1/text-to-speech/nxo2TAmShnYtYe9wngSQ\"\n",
        "\n",
        "headers = {\n",
        "  \"Accept\": \"audio/mpeg\",\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"xi-api-key\": \"ELEVEN_LABS_API\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "  \"text\": f\"{content}\",\n",
        "  \"model_id\": \"eleven_monolingual_v1\",\n",
        "  \"voice_settings\": {\n",
        "    \"stability\": 0.5,\n",
        "    \"similarity_boost\": 0.5\n",
        "  }\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data, headers=headers)\n",
        "with open('output.mp3', 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx92QjH4kIC8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
